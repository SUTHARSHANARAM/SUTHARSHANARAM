{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEjsx4Qvi+LA4Y7pXT7OZe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SUTHARSHANARAM/SUTHARSHANARAM/blob/main/Spark%20program%20to%20perform%20regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KLVctoWQsBa",
        "outputId": "09191085-74f8-456b-936c-0bd209293adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+-----+\n",
            "|feature1|feature2|label|\n",
            "+--------+--------+-----+\n",
            "|     1.0|     2.0|  3.0|\n",
            "|     2.0|     1.0|  2.5|\n",
            "|     3.0|     3.0|  6.0|\n",
            "|     4.0|     5.0|  9.0|\n",
            "|     5.0|     3.0|  7.5|\n",
            "|     6.0|     6.0| 12.0|\n",
            "|     7.0|     8.0| 15.0|\n",
            "+--------+--------+-----+\n",
            "\n",
            "+---------+-----+------------------+\n",
            "| features|label|        prediction|\n",
            "+---------+-----+------------------+\n",
            "|[3.0,3.0]|  6.0| 5.789473684210524|\n",
            "|[6.0,6.0]| 12.0|11.828947368421058|\n",
            "+---------+-----+------------------+\n",
            "\n",
            "Coefficients: [0.825657894736843,1.1875000000000018]\n",
            "Intercept: -0.2500000000000109\n",
            "RMSE: 0.19180762811990992\n",
            "R2: 0.9959122037550016\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"LinearRegressionExample\").getOrCreate()\n",
        "\n",
        "# Sample data (replace or expand as needed)\n",
        "data = [\n",
        "    Row(feature1=1.0, feature2=2.0, label=3.0),\n",
        "    Row(feature1=2.0, feature2=1.0, label=2.5),\n",
        "    Row(feature1=3.0, feature2=3.0, label=6.0),\n",
        "    Row(feature1=4.0, feature2=5.0, label=9.0),\n",
        "    Row(feature1=5.0, feature2=3.0, label=7.5),\n",
        "    Row(feature1=6.0, feature2=6.0, label=12.0),\n",
        "    Row(feature1=7.0, feature2=8.0, label=15.0)\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "df.show()\n",
        "\n",
        "# Step 1: Assemble features into a single vector column\n",
        "assembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\"], outputCol=\"features\")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Step 2: Prepare the data for training\n",
        "df = df.select(\"features\", \"label\")\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=123)\n",
        "\n",
        "# Step 4: Define and fit the linear regression model\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "# Step 5: Make predictions on the test set\n",
        "test_predictions = lr_model.transform(test_data)\n",
        "test_predictions.select(\"features\", \"label\", \"prediction\").show()\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "print(\"Coefficients:\", lr_model.coefficients)\n",
        "print(\"Intercept:\", lr_model.intercept)\n",
        "\n",
        "# Evaluate model performance on test data\n",
        "test_summary = lr_model.evaluate(test_data)\n",
        "print(\"RMSE:\", test_summary.rootMeanSquaredError)\n",
        "print(\"R2:\", test_summary.r2)\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()\n"
      ]
    }
  ]
}